{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Of course. Here is a complete Colab Enterprise notebook that accomplishes your goal.\n",
        "\n",
        "This notebook provides the full Python code and explanatory markdown to query products lacking images from BigQuery, generate new images using Vertex AI's Imagen model, store them in Google Cloud Storage, and log the new image paths back into a BigQuery table.\n",
        "\n",
        "-----\n",
        "\n",
        "# üì∏ Product Image Generation with Vertex AI and BigQuery\n",
        "\n",
        "This notebook automates the process of identifying products in a BigQuery catalog that are missing images and using a generative AI model (Vertex AI Imagen) to create and store new product photos.\n",
        "\n",
        "**The workflow is as follows:**\n",
        "\n",
        "1.  **Query BigQuery**: Fetch a list of products where the `image_url` is missing.\n",
        "2.  **Generate Image**: For each product, create a descriptive prompt from its metadata (e.g., name, category, description) and use Vertex AI Imagen to generate a new image.\n",
        "3.  **Store in GCS**: Upload the generated image file to a specified Google Cloud Storage (GCS) bucket.\n",
        "4.  **Log to BigQuery**: Record the GCS path of the new image in a log table for tracking and integration.\n",
        "\n",
        "-----\n",
        "\n",
        "## ‚öôÔ∏è 1. Setup and Configuration\n",
        "\n",
        "First, let's install the necessary libraries and authenticate. In a Colab Enterprise environment, authentication is typically handled seamlessly."
      ],
      "metadata": {
        "id": "Ts3QwVLjrZk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required Google Cloud libraries\n",
        "!pip install --upgrade google-cloud-aiplatform google-cloud-bigquery google-cloud-storage pandas db-dtypes\n",
        "\n",
        "# Authenticate and initialize clients\n",
        "import google.colab.auth\n",
        "from google.cloud import aiplatform, bigquery, storage\n",
        "import pandas as pd\n",
        "\n",
        "# Authenticate user\n",
        "##google.colab.auth.authenticate_user()\n",
        "\n",
        "print(\"Libraries installed and authenticated successfully!\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "jwF2ZZDYrZk2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, configure the variables for your specific GCP environment. **You must change these values to match your project setup.**"
      ],
      "metadata": {
        "id": "dM1fAVRxrZk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- USER CONFIGURATION ---\n",
        "\n",
        "# GCP Project Details\n",
        "PROJECT_ID = \"partarch-ecommerce-demo\"  # @param {type:\"string\"}\n",
        "REGION = \"us-central1\"            # @param {type:\"string\"}\n",
        "\n",
        "# BigQuery Details\n",
        "BQ_DATASET_ID = \"retail\"                  # @param {type:\"string\"}\n",
        "BQ_PRODUCTS_VIEW = \"view_product_wo_image\"  # @param {type:\"string\"}\n",
        "BQ_IMAGE_LOG_TABLE = \"generated_image_log\"         # @param {type:\"string\"}\n",
        "BQ_QUERY_LIMIT = 10 # @param {type:\"integer\"}\n",
        "\n",
        "# Google Cloud Storage Details\n",
        "GCS_BUCKET_NAME = \"partarch-ecommerce-demo-images\" # @param {type:\"string\"}\n",
        "\n",
        "# --- IMAGE GENERATION CONFIGURATION ---\n",
        "\n",
        "# See model documentation for all options: https://cloud.google.com/vertex-ai/docs/generative-ai/image/overview\n",
        "NUMBER_OF_IMAGES_TO_GENERATE = 1  # Number of images to generate per product\n",
        "IMAGE_STYLE_PRESET = \"photorealistic\" # Options: \"photorealistic\", \"digital_art\", \"cinematic\", etc.\n",
        "ASPECT_RATIO = \"1:1\" # Options: \"1:1\", \"16:9\", \"9:16\", etc.\n",
        "SAFETY_FILTER_LEVEL = \"block_few\" # Options: \"block_most\", \"block_some\", \"block_few\". \"block_few\" is the most permissive.\n",
        "PROMPT_TEMPLATE = \"\"\"\n",
        "A professional, high-resolution product photograph of a {categories},\n",
        "specifically: {description}.\n",
        "The product is centered on a clean, solid light-grey background.\n",
        "The lighting is bright and even, highlighting the product's features.\n",
        "Style: {style}.\n",
        "\"\"\"\n",
        "\n",
        "# --- INITIALIZE CLIENTS ---\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
        "bq_client = bigquery.Client(project=PROJECT_ID)\n",
        "storage_client = storage.Client(project=PROJECT_ID)\n",
        "\n",
        "print(f\"Configuration loaded for project: {PROJECT_ID}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "8EDFE5mOrZk3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## üìä 2. Fetch Products from BigQuery\n",
        "\n",
        "This function queries your BigQuery view to get the list of products that need an image. We'll use a `LIMIT` clause to control how many products we process in one run, which is useful for testing.\n",
        "\n",
        "**Prerequisite**: You need a view in BigQuery (`products_without_images_view`) that returns at least `product_id`, `product_description`, and `product_category` for products where an image URL is not present."
      ],
      "metadata": {
        "id": "sNPVsZj7rZk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_products_without_images(limit: int = 1000) -> pd.DataFrame:\n",
        "    \"\"\"Queries BigQuery to get a list of products with no image URL.\n",
        "\n",
        "    Args:\n",
        "        limit: The maximum number of products to fetch.\n",
        "\n",
        "    Returns:\n",
        "        A pandas DataFrame containing product data.\n",
        "    \"\"\"\n",
        "    print(f\"Fetching up to {limit} products from BigQuery...\")\n",
        "    query = f\"\"\"\n",
        "        SELECT\n",
        "            id,\n",
        "            title,\n",
        "            description,\n",
        "            categories\n",
        "        FROM\n",
        "            `{PROJECT_ID}.{BQ_DATASET_ID}.{BQ_PRODUCTS_VIEW}`\n",
        "        LIMIT {limit}\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = bq_client.query(query).to_dataframe()\n",
        "        print(f\"Successfully fetched {len(df)} products.\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while querying BigQuery: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# Fetch the product data\n",
        "products_df = fetch_products_without_images(limit=BQ_QUERY_LIMIT)\n",
        "display(products_df)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "4qKXfVKXrZk3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## üé® 3. Generate and Store Product Image\n",
        "\n",
        "This function takes the data for a single product, builds a descriptive prompt, calls the Vertex AI Imagen model to generate the image, and then uploads the resulting image file to your GCS bucket."
      ],
      "metadata": {
        "id": "3ddxmiQ3rZk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vertexai.preview.vision_models import ImageGenerationModel\n",
        "import traceback\n",
        "\n",
        "def generate_and_store_image(id: str, title: str, description: str, categories: str) -> str:\n",
        "    \"\"\"\n",
        "    Generates an image based on product data and stores it in GCS.\n",
        "\n",
        "    Args:\n",
        "        id: The unique identifier for the product.\n",
        "        title: The title or name of the product.\n",
        "        description: The description of the product.\n",
        "        categories: The product's categories.\n",
        "\n",
        "    Returns:\n",
        "        The GCS URI of the stored image (e.g., \"gs://bucket/image.png\").\n",
        "        Returns an empty string if generation or upload fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 1. Construct the detailed prompt\n",
        "        prompt = PROMPT_TEMPLATE.format(\n",
        "            categories=categories,\n",
        "            description=description,\n",
        "            style=IMAGE_STYLE_PRESET\n",
        "        )\n",
        "        print(f\"   Prompt for product '{id}':\\n   '{prompt[:150]}...'\")\n",
        "\n",
        "        # 2. Initialize the model and generate the image\n",
        "        model = ImageGenerationModel.from_pretrained(\"imagegeneration@006\")\n",
        "        response = model.generate_images(\n",
        "            prompt=prompt,\n",
        "            number_of_images=NUMBER_OF_IMAGES_TO_GENERATE,\n",
        "            aspect_ratio=ASPECT_RATIO,\n",
        "            safety_filter_level=SAFETY_FILTER_LEVEL\n",
        "        )\n",
        "\n",
        "        # 3. **Crucial Check**: Ensure the model returned an image.\n",
        "        if not response.images:\n",
        "            print(f\"‚ö†Ô∏è Model returned no images for product '{id}'. This might be due to safety filters or a problematic prompt.\")\n",
        "            return \"\"\n",
        "\n",
        "        image_bytes = response.images[0]._image_bytes\n",
        "\n",
        "        # 4. Upload the image to Google Cloud Storage\n",
        "        bucket = storage_client.get_bucket(GCS_BUCKET_NAME)\n",
        "        blob_name = f\"product_images/{id}.png\"\n",
        "        blob = bucket.blob(blob_name)\n",
        "\n",
        "        blob.upload_from_string(image_bytes, content_type=\"image/png\")\n",
        "        gcs_uri = f\"gs://{GCS_BUCKET_NAME}/{blob_name}\"\n",
        "\n",
        "        print(f\"‚úÖ Image for product '{id}' successfully stored at: {gcs_uri}\")\n",
        "        return gcs_uri\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to generate or store image for product '{id}': {e}\")\n",
        "        print(\"   --- Full Error Traceback ---\")\n",
        "        print(traceback.format_exc())\n",
        "        print(\"   --------------------------\")\n",
        "        return \"\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "lBDoiDV_rZk3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## üìù 4. Log Image Path to BigQuery\n",
        "\n",
        "After a new image is successfully created and stored, this function logs the `product_id` and the new `gcs_uri` into a tracking table in BigQuery.\n",
        "\n",
        "**Prerequisite**: You need a table in BigQuery (`generated_image_log`) with at least these columns: `product_id` (STRING), `gcs_uri` (STRING), and `log_timestamp` (TIMESTAMP)."
      ],
      "metadata": {
        "id": "ILXgxpVbrZk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log_image_path_to_bigquery(id: str, gcs_uri: str):\n",
        "    \"\"\"\n",
        "    Inserts a record into a BigQuery log table.\n",
        "\n",
        "    Args:\n",
        "        id: The ID of the product.\n",
        "        gcs_uri: The GCS path of the generated image.\n",
        "    \"\"\"\n",
        "    table_ref = bq_client.dataset(BQ_DATASET_ID).table(BQ_IMAGE_LOG_TABLE)\n",
        "    rows_to_insert = [\n",
        "        {\n",
        "            \"id\": id,\n",
        "            \"gcs_uri\": gcs_uri,\n",
        "            \"log_timestamp\": pd.Timestamp.now().isoformat()\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    errors = bq_client.insert_rows_json(table_ref, rows_to_insert)\n",
        "    if not errors:\n",
        "        print(f\"   Successfully logged path for product '{id}' to BigQuery.\")\n",
        "    else:\n",
        "        print(f\"   Encountered errors while inserting rows to BigQuery: {errors}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "lESIIE00rZk4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## üöÄ 5. Run the Full Workflow\n",
        "\n",
        "This final step orchestrates the entire process. It iterates through the DataFrame of products fetched in step 2 and calls the generation, storage, and logging functions for each one."
      ],
      "metadata": {
        "id": "7xMu32OLrZk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not products_df.empty:\n",
        "    print(\"\\nStarting the image generation workflow...\\n\" + \"=\"*40)\n",
        "\n",
        "    for index, row in products_df.iterrows():\n",
        "        product_id = row['id']\n",
        "        print(f\"Processing Product ID: {product_id} ({index + 1}/{len(products_df)})\")\n",
        "\n",
        "        # Step 1: Generate and store the image\n",
        "        gcs_path = generate_and_store_image(\n",
        "            id=product_id,\n",
        "            title=row['title'],\n",
        "            description=row['description'],\n",
        "            categories=row['categories']\n",
        "        )\n",
        "\n",
        "        # Step 2: If successful, log the new path to BigQuery\n",
        "        if gcs_path:\n",
        "            log_image_path_to_bigquery(product_id, gcs_path)\n",
        "\n",
        "        print(\"-\" * 20)\n",
        "\n",
        "    print(\"=\"*40 + \"\\nWorkflow finished!\")\n",
        "else:\n",
        "    print(\"No products found that need images. All done!\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "zpv0pbpGrZk4"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "vertex_ai_generate_image.ipynb"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}